{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Spotify Most Streamed Songs Analysis\n",
    "\n",
    "## Overview\n",
    "\n",
    "This project analyzes and predicts the number of Spotify charts (`in_spotify_charts`) a song appears in, using various song attributes. It leverages machine learning regression models to identify key factors influencing a song's chart presence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('spotify_streams.csv')\n",
    "\n",
    "# Clean data\n",
    "# Drop columns\n",
    "columns_to_drop = [\n",
    "    'track_name',\n",
    "    'artist(s)_name',\n",
    "    'in_apple_charts', \n",
    "    'in_apple_playlists', \n",
    "    'in_deezer_playlists', \n",
    "    'in_deezer_charts', \n",
    "    'in_shazam_charts',\n",
    "    # 'key',\n",
    "    'cover_url',\n",
    "    'streams',\n",
    "    'in_spotify_playlists',\n",
    "    'released_year',\n",
    "    'released_month',\n",
    "    'released_day',  # Optionally drop if not useful\n",
    "]\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Encode categorial variables\n",
    "data['mode'] = data['mode'].map({'Major':1, 'Minor':0})\n",
    "data = pd.get_dummies(data, columns=['key'], drop_first=True)\n",
    "\n",
    "# Convert boolean to integer for 'key' dummy variables\n",
    "key_columns = [col for col in data.columns if col.startswith('key_')]\n",
    "data[key_columns] = data[key_columns].astype(int)\n",
    "\n",
    "print(data.info())\n",
    "\n",
    "# # View the first few rows\n",
    "data.head()\n",
    "\n",
    "# # Summary statistics\n",
    "# print(data.describe())\n",
    "\n",
    "# # # Data types and missing values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Numerical Features Distribution\n",
    "numeric_features = ['artist_count', 'bpm', 'danceability_%',\n",
    "                    'valence_%', 'energy_%', 'acousticness_%',\n",
    "                    'instrumentalness_%', 'liveness_%', 'speechiness_%']\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "for i, feature in enumerate(numeric_features, 1):\n",
    "    plt.subplot(5, 2, i)\n",
    "    sns.histplot(data[feature], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Categorical Features Distribution\n",
    "# 'mode' is already encoded, so we can plot its distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='mode', data=data)\n",
    "plt.title('Distribution of Mode (Major=1, Minor=0)')\n",
    "plt.xlabel('Mode')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Correlation Analysis\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "corr = data.corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify highly correlated features with the target\n",
    "target = 'in_spotify_charts'\n",
    "correlations = data.corr()[target].sort_values(ascending=False)\n",
    "print(\"\\nCorrelations with Target Variable:\")\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Determine Data Transformations\n",
    "\n",
    "# Check skewness of the target variable\n",
    "print(f\"\\nSkewness of '{target}': {data[target].skew()}\")\n",
    "\n",
    "# Apply log transformation if skewness is high\n",
    "if abs(data[target].skew()) > 1:\n",
    "    data[target] = np.log1p(data[target])\n",
    "    print(f\"Applied log transformation to '{target}'. New skewness: {data[target].skew()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Handle Outliers\n",
    "\n",
    "# Boxplot to identify outliers in numerical features\n",
    "plt.figure(figsize=(15, 20))\n",
    "for i, feature in enumerate(numeric_features, 1):\n",
    "    plt.subplot(5, 2, i)\n",
    "    sns.boxplot(x=## 5. Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numeric_features_scaled = ['artist_count', 'bpm', 'danceability_%',\n",
    "                           'valence_%', 'energy_%', 'acousticness_%',\n",
    "                           'instrumentalness_%', 'liveness_%', 'speechiness_%']\n",
    "\n",
    "data[numeric_features_scaled] = scaler.fit_transform(data[numeric_features_scaled])\n",
    "\n",
    "# Display scaled features\n",
    "print(\"\\nScaled Numerical Features:\")\n",
    "print(data[numeric_features_scaled].head())data[feature])\n",
    "    plt.title(f'Boxplot of {feature}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Decide on outlier treatment (e.g., capping)\n",
    "from scipy import stats\n",
    "\n",
    "# Example: Remove data points with z-score > 3\n",
    "z_scores = np.abs(stats.zscore(data[numeric_features]))\n",
    "data = data[(z_scores < 3).all(axis=1)]\n",
    "print(f\"\\nData shape after removing outliers: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numeric_features_scaled = ['artist_count', 'bpm', 'danceability_%',\n",
    "                           'valence_%', 'energy_%', 'acousticness_%',\n",
    "                           'instrumentalness_%', 'liveness_%', 'speechiness_%']\n",
    "\n",
    "data[numeric_features_scaled] = scaler.fit_transform(data[numeric_features_scaled])\n",
    "\n",
    "# Display scaled features\n",
    "print(\"\\nScaled Numerical Features:\")\n",
    "print(data[numeric_features_scaled].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Final Feature Set\n",
    "# Define target variable\n",
    "y = data['in_spotify_charts']\n",
    "\n",
    "# Define feature set (drop target)\n",
    "X = data.drop(['in_spotify_charts'], axis=1)\n",
    "\n",
    "# Display feature set\n",
    "print(\"\\nFeature Set (X):\")\n",
    "print(X.head())\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "\n",
    "## 1. Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"\\nLinear Regression:\")\n",
    "print(f\"MSE: {mse_lr:.2f}\")\n",
    "print(f\"MAE: {mae_lr:.2f}\")\n",
    "print(f\"R2 Score: {r2_lr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Regressor:\")\n",
    "print(f\"MSE: {mse_rf:.2f}\")\n",
    "print(f\"MAE: {mae_rf:.2f}\")\n",
    "print(f\"R2 Score: {r2_rf:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Hyperparameter Tuning with GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Parameters from GridSearchCV:\", grid_rf.best_params_)\n",
    "print(\"Best Cross-Validation MSE:\", -grid_rf.best_score_)\n",
    "\n",
    "# Best model predictions\n",
    "best_rf = grid_rf.best_estimator_\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mse_best_rf = mean_squared_error(y_test, y_pred_best_rf)\n",
    "mae_best_rf = mean_absolute_error(y_test, y_pred_best_rf)\n",
    "r2_best_rf = r2_score(y_test, y_pred_best_rf)\n",
    "\n",
    "print(\"\\nTuned Random Forest Regressor:\")\n",
    "print(f\"MSE: {mse_best_rf:.2f}\")\n",
    "print(f\"MAE: {mae_best_rf:.2f}\")\n",
    "print(f\"R2 Score: {r2_best_rf:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Compare All Models\n",
    "model_performance = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Random Forest', 'Tuned Random Forest'],\n",
    "    'MSE': [mse_lr, mse_rf, mse_best_rf],\n",
    "    'MAE': [mae_lr, mae_rf, mae_best_rf],\n",
    "    'R2 Score': [r2_lr, r2_rf, r2_best_rf]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(model_performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Feature Importance Analysis\n",
    "\n",
    "### 6.1 Tuned Random Forest\n",
    "importances_best = best_rf.feature_importances_\n",
    "feature_importances_best = pd.Series(importances_best, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x=feature_importances_best, y=feature_importances_best.index)\n",
    "plt.title('Tuned Random Forest Feature Importances')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this project, we aimed to predict the number of Spotify charts a song appears in using three regression models: Linear Regression, Random Forest Regressor, and Tuned Random Forest Regressor. The performance of each model is summarized below:\n",
    "\n",
    "| Model                | MSE      | MAE      | R² Score |\n",
    "|----------------------|----------|----------|----------|\n",
    "| Linear Regression    | 2.1389   | 1.2992   | 0.0304   |\n",
    "| Random Forest        | 2.3009   | 1.3524   | -0.0430  |\n",
    "| Tuned Random Forest  | 2.1953   | 1.3249   | 0.0049   |\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "- **Linear Regression** achieved an R² score of **0.0304**, indicating it explains approximately **3%** of the variance in the target variable. While slightly better than random guessing, the model's predictive power is minimal.\n",
    "\n",
    "- **Random Forest Regressor** resulted in a negative R² score of **-0.0430**, suggesting that it performs worse than a simple mean predictor. This may be due to overfitting or irrelevant feature inclusion.\n",
    "\n",
    "- **Tuned Random Forest Regressor** showed a marginal improvement with an R² score of **0.0049**, still indicating poor performance and negligible explanatory power.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The regression models developed in this study exhibit limited effectiveness in predicting the number of Spotify charts a song appears in. The low and negative R² scores across models suggest that the current feature set and model configurations are insufficient to capture the underlying factors influencing chart presence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
