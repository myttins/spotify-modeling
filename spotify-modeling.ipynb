{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('spotify_streams.csv')\n",
    "\n",
    "# Clean data\n",
    "# Drop columns\n",
    "columns_to_drop = [\n",
    "    'track_name',\n",
    "    'artist(s)_name',\n",
    "    'in_apple_charts', \n",
    "    'in_apple_playlists', \n",
    "    'in_deezer_playlists', \n",
    "    'in_deezer_charts', \n",
    "    'in_shazam_charts',\n",
    "    # 'key',\n",
    "    'cover_url',\n",
    "    'streams',\n",
    "    'in_spotify_playlists',\n",
    "    'released_year',\n",
    "    'released_month',\n",
    "    'released_day',  # Optionally drop if not useful\n",
    "]\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "# # Convert streams to numerical - removed streams for now\n",
    "# columns_to_clean = ['streams']\n",
    "# for column in columns_to_clean:\n",
    "#     data[column] = data[column].str.replace(',', '')  # Remove commas\n",
    "#     data[column] = pd.to_numeric(data[column], errors='coerce')  # Convert to numeric\n",
    "\n",
    "# # Fill NaN in numerical columns with 0\n",
    "# data['streams'] = data['streams'].fillna(0)\n",
    "\n",
    "# Fill NaN in 'key' with 'Unknown' (or another meaningful placeholder)\n",
    "# data['key'] = data['key'].fillna('Unknown')\n",
    "\n",
    "# Encode categorial variables\n",
    "data['mode'] = data['mode'].map({'Major':1, 'Minor':0})\n",
    "data = pd.get_dummies(data, columns=['key'], drop_first=True)\n",
    "\n",
    "# Convert boolean to integer for 'key' dummy variables\n",
    "key_columns = [col for col in data.columns if col.startswith('key_')]\n",
    "data[key_columns] = data[key_columns].astype(int)\n",
    "\n",
    "# # Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# # View the first few rows\n",
    "print(data.head())\n",
    "\n",
    "# # Summary statistics\n",
    "# print(data.describe())\n",
    "\n",
    "# # # Data types and missing values\n",
    "print(data.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of in_spotify_charts\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(data['in_spotify_charts'], kde=True)\n",
    "plt.title('Distribution of Songs in Spotify Charts')\n",
    "plt.xlabel('Number of Spotify Charts')\n",
    "plt.ylabel('Frequency (Number of Songs)')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of BPM\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(data['bpm'], kde=True)\n",
    "plt.title('Distribution of BPM')\n",
    "plt.xlabel('Beats Per Minute (BPM)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,10))\n",
    "# corr = data.corr()\n",
    "# sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "# plt.title('Correlation Heatmap')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Ensure only numeric columns are used for the correlation matrix\n",
    "numeric_data = data.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr = numeric_data.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numeric_features = ['artist_count', 'bpm', 'danceability_%',\n",
    "                    'valence_%', 'energy_%', 'acousticness_%',\n",
    "                    'instrumentalness_%', 'liveness_%', 'speechiness_%']\n",
    "\n",
    "data[numeric_features] = scaler.fit_transform(data[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variable\n",
    "y = data['in_spotify_charts']\n",
    "\n",
    "# Check skewness and apply log transformation if needed\n",
    "print(f\"Skewness of target: {y.skew()}\")\n",
    "\n",
    "if y.skew() > 1 or y.skew() < -1:\n",
    "    y = np.log1p(y)  # Log transform\n",
    "\n",
    "# Define feature set (drop target)\n",
    "X = data.drop(['in_spotify_charts'], axis=1)\n",
    "\n",
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"Linear Regression:\")\n",
    "print(f\"MSE: {mse_lr:.2f}\")\n",
    "print(f\"MAE: {mae_lr:.2f}\")\n",
    "print(f\"R2 Score: {r2_lr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Regressor:\")\n",
    "print(f\"MSE: {mse_rf:.2f}\")\n",
    "print(f\"MAE: {mae_rf:.2f}\")\n",
    "print(f\"R2 Score: {r2_rf:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning with GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_rf.best_params_)\n",
    "print(\"Best Cross-Validation MSE:\", -grid_rf.best_score_)\n",
    "\n",
    "best_rf = grid_rf.best_estimator_\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "\n",
    "mse_best_rf = mean_squared_error(y_test, y_pred_best_rf)\n",
    "mae_best_rf = mean_absolute_error(y_test, y_pred_best_rf)\n",
    "r2_best_rf = r2_score(y_test, y_pred_best_rf)\n",
    "\n",
    "print(\"Tuned Random Forest Regressor:\")\n",
    "print(f\"MSE: {mse_best_rf:.2f}\")\n",
    "print(f\"MAE: {mae_best_rf:.2f}\")\n",
    "print(f\"R2 Score: {r2_best_rf:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Regressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"XGBoost Regressor:\")\n",
    "print(f\"MSE: {mse_xgb:.2f}\")\n",
    "print(f\"MAE: {mae_xgb:.2f}\")\n",
    "print(f\"R2 Score: {r2_xgb:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Models\n",
    "model_performance = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Random Forest', 'Tuned Random Forest', 'XGBoost Regressor'],\n",
    "    'MSE': [mse_lr, mse_rf, mse_best_rf, mse_xgb],\n",
    "    'MAE': [mae_lr, mae_rf, mae_best_rf, mae_xgb],\n",
    "    'R2 Score': [r2_lr, r2_rf, r2_best_rf, r2_xgb]\n",
    "})\n",
    "\n",
    "print(model_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importances for Tuned Random Forest\n",
    "importances_best = best_rf.feature_importances_\n",
    "feature_importances_best = pd.Series(importances_best, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x=feature_importances_best, y=feature_importances_best.index)\n",
    "plt.title('Tuned Random Forest Feature Importances')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importances for XGBoost\n",
    "importances_xgb = xgb.feature_importances_\n",
    "feature_importances_xgb = pd.Series(importances_xgb, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x=feature_importances_xgb, y=feature_importances_xgb.index)\n",
    "plt.title('XGBoost Feature Importances')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
